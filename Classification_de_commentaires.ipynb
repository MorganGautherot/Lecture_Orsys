{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Classification_de_commentaires.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Indentifying spam in YouTube video comments using RNNs"],"metadata":{"id":"nj4-kYbvERyC"}},{"cell_type":"markdown","source":["Tout les jours des centaines de milliers de commentaires sont déposés sur YouTube, certains sont de réels commentaires et d'autres sont des publicités déposés par des bots. \n","\n","Il n'est pas réaliste de penser que des humains puissent modérer autant de commentaires.\n","\n","Des modèles de machines learning sont entraîner pour modérer automatiquement ces commentaires. \n","\n","Dans ce notebook, vous allez devoir entraîner un modèle de classificaiton de spam pour résoudre ce problème."],"metadata":{"id":"iw1ZY7ReI4pc"}},{"cell_type":"markdown","source":["# Importation des packages"],"metadata":{"id":"Ut4tP7vyOTPf"}},{"cell_type":"code","source":["import tensorflow as tf\n","import pandas as pd\n","import numpy as np\n","from sklearn import model_selection\n","from sklearn import metrics\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.layers import GRU, Dense, Embedding\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.losses import BinaryCrossentropy\n","from tensorflow.keras.optimizers import Adam"],"metadata":{"id":"MCprzZz-OVe7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Importation des données"],"metadata":{"id":"Y_frihmIHsjI"}},{"cell_type":"markdown","source":["Ajoutez un raccourci de ce dossier à votre google drive :\n","\n","https://drive.google.com/drive/folders/1RwEnJX3JHL1-VGvKTuZKAQWMlZ9EbR5o?usp=sharing"],"metadata":{"id":"pR_eJQVIHOzl"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"OwXCHrSsDhd7"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","source":["comments_df_list = []\n","comments_file = ['drive/MyDrive/Data_YouTube/Youtube01-Psy.csv',\n","                 'drive/MyDrive/Data_YouTube/Youtube02-KatyPerry.csv',\n","                 'drive/MyDrive/Data_YouTube/Youtube03-LMFAO.csv',\n","                 'drive/MyDrive/Data_YouTube/Youtube04-Eminem.csv',\n","                 'drive/MyDrive/Data_YouTube/Youtube05-Shakira.csv']\n","for f in comments_file:\n","    df = pd.read_csv(f,header=0)\n","    comments_df_list.append(df)\n","comments_df = pd.concat(comments_df_list)\n","comments_df = comments_df.sample(frac=1.0, random_state=123)\n","print(comments_df.shape)\n","comments_df = comments_df.reset_index(drop=True)\n","comments_df.head(5)"],"metadata":{"id":"f0hQcQCqHgLC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["comments_df['CONTENT'] = comments_df['CONTENT'].apply(lambda x : x.replace('\\ufeff', ''))\n","comments_df['CONTENT'] = comments_df['CONTENT'].apply(lambda x : x.replace('\\xa0', ''))\n","comments_df['CONTENT'] = comments_df['CONTENT'].apply(lambda x : x.replace('&#39;', ' '))"],"metadata":{"id":"gIc_soxl0DSl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["comments_df.loc[1, 'CONTENT']"],"metadata":{"id":"T35o1Q3Sz51R"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exploration du jeu de données"],"metadata":{"id":"aUOta7BCKTTm"}},{"cell_type":"markdown","source":["Visualiser le nombre de spam et le nombre de commentaire réel avec un barplot.\n","\n","N'hésitez pas à vous aider de la [documentation](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.bar.html#examples-using-matplotlib-pyplot-bar)."],"metadata":{"id":"9Fcn6Y2sKXIw"}},{"cell_type":"code","source":["### Your code ###"],"metadata":{"id":"qw6VR7YvH91Q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Calculez le nombre de mots maximum dans un commentaire."],"metadata":{"id":"ii1Z55ABMRcI"}},{"cell_type":"code","source":["max_length = None\n","print(\"Taille du commentaire le plus long : {}\".format(max_length))"],"metadata":{"id":"hc3E3gr3K_PP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Calculez le nombre de mots moyen dans un commentaire."],"metadata":{"id":"LAaBIOyRMYXQ"}},{"cell_type":"code","source":["average_size = None\n","print(\"Taille Moyenne d'un commentaire : {} \".format(average_size))"],"metadata":{"id":"yKNtobEQMa5D"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Prétraitement des données "],"metadata":{"id":"7JRAioecNDy2"}},{"cell_type":"markdown","source":["Hyperparamètres"],"metadata":{"id":"yIiC74kDOBsx"}},{"cell_type":"code","source":["oov_token = \"<UNK>\"\n","truncating = 'post'\n","padding = 'post'"],"metadata":{"id":"2WZaIyrcODvt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Initialiser le tokenizer. \n","\n","Utilisez en paramètre *oov_token=oovtoken*\n","\n","N'hésitez pas à checker la [doc](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer). \n","\n","N'hésitez pas à lire cette [réponse](https://stackoverflow.com/questions/51956000/what-does-keras-tokenizer-method-exactly-do) de stack overflow pour comprendre ce que fait réellement *Tokenizer*."],"metadata":{"id":"TIl8f0RgN6pO"}},{"cell_type":"code","source":["tokenizer = None"],"metadata":{"id":"wQv-FagNMcM8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Entraîner le texte sur le texte en utilisant la fonction *fit_on_texts*.\n","\n","N'hésitez pas à lire la [doc](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer#fit_on_texts)."],"metadata":{"id":"cu-m4v5MOkNQ"}},{"cell_type":"code","source":["None"],"metadata":{"id":"XPYXt63MNGZ4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Visualiser le dictionnaire de mapping d'un mots à sont identifiant créer durant l'entraînement.\n","\n","Utilisez l'attribut *word_index*."],"metadata":{"id":"HM1qGn_9PMOe"}},{"cell_type":"code","source":["word_index = None"],"metadata":{"id":"iOYX4_zcPZAc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Calculer le nombre maximum de mots dans notre corpus."],"metadata":{"id":"0UQNO9QAP_rl"}},{"cell_type":"code","source":["vocab_size = None\n","print(vocab_size)"],"metadata":{"id":"BwRnXBteP7Ty"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Appliquer la transformation sur nos données en utilisant la fonction *texts_to_sequences*.\n","\n","N'hésitez pas à lire la [doc](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer#texts_to_sequences)."],"metadata":{"id":"VnvLSh1pPSF-"}},{"cell_type":"code","source":["x = None"],"metadata":{"id":"SjA9b7_3QNyc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Comme vous pouvez le voir ci-dessous, toutes les séquences n'ont pas les mêmes longueurs. "],"metadata":{"id":"P0xvBE4cQRgp"}},{"cell_type":"code","source":["print(\"Longueur du premier commentaire : {}\".format(len(x[0])))\n","print(\"Longueur du deuxième commentaire : {}\".format(len(x[1])))"],"metadata":{"id":"U5MJb7UjQgxJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Pourtant votre réseau de neurone à besoin d'une taille de séquences fixe pour s'entraîner. \n","\n","Il va falloir ajouter des caractères à la fin des plus petits commentaires pour obtenir une même taille pour tous. \n","\n","Ce procédé ce nomme padding. \n","\n","Utilisez la fonction *pad_sequences* sur vos données.\n","\n","Dans les hyperparamètres utiliser :\n","- *padding = padding*\n","- *truncating=truncating*\n","\n","N'hésitez pas à lire la [documentation](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences)."],"metadata":{"id":"xtgcnRbjRK2o"}},{"cell_type":"code","source":["x = None"],"metadata":{"id":"yph7CpLRN5hq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Visualiser la dimension de la mtrice que vosu avez obtenu."],"metadata":{"id":"Ch9sIHaGf9oG"}},{"cell_type":"code","source":["x.shape"],"metadata":{"id":"J5qWPRPSgB6G"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Visualisons l'exemple 1 après les pré traitements."],"metadata":{"id":"k_4CzjYSBncx"}},{"cell_type":"code","source":["x[1]"],"metadata":{"id":"MVkudQmot7fC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Visualisons l'exemple 1 avant l'entraînement."],"metadata":{"id":"L7vwx7fUBvuP"}},{"cell_type":"code","source":["comments_df.loc[1, 'CONTENT']"],"metadata":{"id":"6zL7wHF3vI8M"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Vérifions la correspondance entre le mot et son indice."],"metadata":{"id":"lWYsY2cLByWV"}},{"cell_type":"code","source":["word_index['awesome']"],"metadata":{"id":"1PJl9JxAybZh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["A quelle classe appartient cette phrase ?"],"metadata":{"id":"jTZUKD4EB2x0"}},{"cell_type":"code","source":["comments_df.loc[1, 'CLASS']"],"metadata":{"id":"-jbqcQZPySqf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Initialisation du modèle "],"metadata":{"id":"pqErZO1B5HO2"}},{"cell_type":"markdown","source":["Hyperparamètres"],"metadata":{"id":"RKezhF3h5HO4"}},{"cell_type":"code","source":["embedding_dim = 100\n","\n","tf.keras.utils.set_random_seed(123)"],"metadata":{"id":"URHWAenX5HO5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["En utilisant le séquentiel ([doc](https://keras.io/guides/sequential_model/)), initialiser un modèle d'apprentissage profond avec :\n","- une couche d'embdedding ([doc](https://keras.io/api/layers/core_layers/embedding/)) (input_dim=vocab_size+1, output_dim=embedding_dim, input_length=max_length)\n","- GRU ([doc](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU)) (unités=64)\n","- Dense avec pour fonction d'activation la sigmoid ([doc](https://keras.io/api/layers/core_layers/dense/)) (unités=1)"],"metadata":{"id":"nQwYO6g_5HO5"}},{"cell_type":"code","source":["model = None"],"metadata":{"id":"3MylZzxq5HO5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Compile "],"metadata":{"id":"rnTB3UMW5HO5"}},{"cell_type":"code","source":["None"],"metadata":{"id":"BVdiwQhi5HO6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Summary"],"metadata":{"id":"duxHFlbO5HO6"}},{"cell_type":"code","source":["None"],"metadata":{"id":"LQ3_xvO_5ZHm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Entraînez votre modèle "],"metadata":{"id":"-TWaoiwc5HO7"}},{"cell_type":"markdown","source":["Hyperparamètres "],"metadata":{"id":"o3QkqRaU5HO7"}},{"cell_type":"code","source":["num_epochs = 200"],"metadata":{"id":"TU-6GJeT5HO7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Séparer vos données en deux jeux, l'entraînement et le test. \n","\n","Utilise zla fonction *train_test_split* de Sklearn.\n","\n","N'hésitez pas à consulter la [doc](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)."],"metadata":{"id":"YDr9T1DI5HO7"}},{"cell_type":"code","source":["x_train, x_test, y_train, y_test = None"],"metadata":{"id":"Zv9jfrS_5HO8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Paramètrage des *callbacks*."],"metadata":{"id":"3S4El5wu5HO8"}},{"cell_type":"code","source":["def scheduler(epoch, lr):\n","  if epoch < 100 :\n","    return lr\n","  elif epoch == 100 :\n","    return lr * 0.1\n","  else :\n","    return lr * np.power(0.99,(epoch / 400))"],"metadata":{"id":"Y6pTMN6x5HO8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["callback = tf.keras.callbacks.LearningRateScheduler(scheduler)"],"metadata":{"id":"_RS3aYUI5HO8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Entraîner votre modèle sur les données x_train et y_test. \n","\n","Utiliser :\n","- données x_test et y_test en validation. \n","- un batch_size de 256\n","- un nombre d'epochs égale à num_epochs\n","\n"],"metadata":{"id":"QhqnU5Rg5HO8"}},{"cell_type":"code","source":["history = None\n","  \n","print(\"Training Complete\")"],"metadata":{"id":"2FrydbJ95HO8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.image  as mpimg\n","import matplotlib.pyplot as plt\n","\n","#-----------------------------------------------------------\n","# Retrieve a list of list results on training and test data\n","# sets for each training epoch\n","#-----------------------------------------------------------\n","acc=model.history.history['accuracy']\n","val_acc=model.history.history['val_accuracy']\n","loss=model.history.history['loss']\n","val_loss=model.history.history['val_loss']\n","\n","epochs=range(len(acc)) # Get number of epochs\n","\n","#------------------------------------------------\n","# Plot training and validation accuracy per epoch\n","#------------------------------------------------\n","plt.plot(epochs, acc, 'r')\n","plt.plot(epochs, val_acc, 'b')\n","plt.title('Training and validation accuracy')\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Accuracy\")\n","plt.legend([\"Accuracy\", \"Validation Accuracy\"])\n","\n","plt.show()\n","\n","#------------------------------------------------\n","# Plot training and validation loss per epoch\n","#------------------------------------------------\n","plt.plot(epochs, loss, 'r')\n","plt.plot(epochs, val_loss, 'b')\n","plt.title('Training and validation loss')\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Loss\")\n","plt.legend([\"Loss\", \"Validation Loss\"])\n","\n","plt.show()"],"metadata":{"id":"q9YqkbHa5HO9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Entraînement en utilisant un pré-entraînement glove"],"metadata":{"id":"TyF-6U9Ry7Vi"}},{"cell_type":"markdown","source":["## Initialisation du modèle"],"metadata":{"id":"s2H_i1qnzOTv"}},{"cell_type":"markdown","source":["Hyperparamètres "],"metadata":{"id":"mD-8wTxazH0l"}},{"cell_type":"code","source":["num_epochs = 200\n","embedding_dim = 100"],"metadata":{"id":"lcW5wUh_A-GF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Création de la matrice d'embedding "],"metadata":{"id":"LRDg3SOpzeAu"}},{"cell_type":"code","source":["embeddings_index = {};\n","\n","with open('/content/drive/MyDrive/RNN_sentiment_dataset/glove.6B.100d.txt') as f:\n","    for line in f:\n","        values = line.split();\n","        word = values[0];\n","        coefs = np.asarray(values[1:], dtype='float32');\n","        embeddings_index[word] = coefs;\n","\n","embeddings_matrix = np.zeros((vocab_size+1, embedding_dim));\n","for word, i in word_index.items():\n","    embedding_vector = embeddings_index.get(word);\n","    if embedding_vector is not None:\n","        embeddings_matrix[i] = embedding_vector;"],"metadata":{"id":"Ssy0liEFziQO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Initialisation du modèle"],"metadata":{"id":"1XvvcP4oznvV"}},{"cell_type":"code","source":["tf.keras.utils.set_random_seed(123)\n","model_emb = None"],"metadata":{"id":"1qk6XCGmzii5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Compilation du modèle "],"metadata":{"id":"UgjNcCZ2z6jf"}},{"cell_type":"code","source":["None"],"metadata":{"id":"0C21uUakz7s1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Summary du modèle"],"metadata":{"id":"CN-xY6TAz8I6"}},{"cell_type":"code","source":["None"],"metadata":{"id":"O81nx922z94c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Entraînement du modèle"],"metadata":{"id":"zaXOJiQP0CdU"}},{"cell_type":"code","source":["history = None\n","  \n","print(\"Training Complete\")"],"metadata":{"id":"BfGdWIpL0Dnt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Visualisation des courbes d'entraînements"],"metadata":{"id":"UbfKifTT0FpL"}},{"cell_type":"code","source":["import matplotlib.image  as mpimg\n","import matplotlib.pyplot as plt\n","\n","#-----------------------------------------------------------\n","# Retrieve a list of list results on training and test data\n","# sets for each training epoch\n","#-----------------------------------------------------------\n","acc_emb=model_emb.history.history['accuracy']\n","val_acc_emb=model_emb.history.history['val_accuracy']\n","loss_emb=model_emb.history.history['loss']\n","val_loss_emb=model_emb.history.history['val_loss']\n","\n","epochs=range(len(acc)) # Get number of epochs\n","\n","#------------------------------------------------\n","# Plot training and validation accuracy per epoch\n","#------------------------------------------------\n","plt.plot(epochs, acc_emb, 'r')\n","plt.plot(epochs, val_acc_emb, 'b')\n","plt.title('Training and validation accuracy')\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Accuracy\")\n","plt.legend([\"Accuracy\", \"Validation Accuracy\"])\n","\n","plt.show()\n","\n","#------------------------------------------------\n","# Plot training and validation loss per epoch\n","#------------------------------------------------\n","plt.plot(epochs, loss_emb, 'r')\n","plt.plot(epochs, val_loss_emb, 'b')\n","plt.title('Training and validation loss')\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Loss\")\n","plt.legend([\"Loss\", \"Validation Loss\"])\n","\n","plt.show()"],"metadata":{"id":"9gml9-iD0IF7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Comparaison des deux modèles"],"metadata":{"id":"fi0JHFTS0RG_"}},{"cell_type":"code","source":["#------------------------------------------------\n","# Plot training and validation accuracy per epoch\n","#------------------------------------------------\n","plt.plot(epochs, val_acc_emb, 'r', label='Pretrain')\n","plt.plot(epochs, val_acc, 'b', label='Train')\n","plt.title('Validation accuracy')\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Accuracy\")\n","plt.legend()\n","\n","plt.show()\n","\n","#------------------------------------------------\n","# Plot training and validation loss per epoch\n","#------------------------------------------------\n","plt.plot(epochs, val_loss_emb, 'r', label='Pretrain')\n","plt.plot(epochs, val_loss, 'b', label='Train')\n","plt.title('Validation loss')\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","\n","plt.show()"],"metadata":{"id":"MeKMtb-d0vcP"},"execution_count":null,"outputs":[]}]}